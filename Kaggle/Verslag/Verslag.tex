\documentclass[a4paper,10pt,twoside]{report}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{titling}
\usepackage{fontspec}
\usepackage{listings}
\usepackage{hyperref}

\usepackage[dvipsnames]{xcolor}


\lstdefinelanguage{Java}{
	keywords=[1]{
	fields, schemaData, dataframe, latMin, latMax, longMin, longMax, rightOuter, leftOuter, lat1, lon1, lat2, lon2, deltaLat, deltaLon, c, d, a, radius, distance, time, tokenizer, remover, assembler, linreg, rfr, trainsetsplit, traintestsplit, indexer, minmax, pipelinerfr, paramgridrfr, pipelinelinreg, trainedlinreg, model, cvmrfr, evaluator, calc, log, metrictype, metrictypes, svc, pca, paramgridsvm, cvsvm, predictionssvm, metrics, predictionsLogReg, predictions, train, test, trainsetsplit, traintestsplit, datasets, createsubsample, pipelinesvm, glr, paramgridglr, gbt, paramgridgbt, pipelineglr, pipelinegbt, predictionsrfr, cvrfr, trainvalidationsplitglr, trainvalidationsplitgbt, range, nietfraudulent, lengte, arrfeatures, kolom, creditcardsubsample, cvmSVM, trainingset, testset, matrix, r1, vectorizer, lr, paramgridlogreg, pipelinelogreg, htf, rfc, paramgridrfc, cvrfc, pipelinerfc, pipelinemodellogreg, predictedlogreg, predictionsrfc},
	keywordstyle=[1]\color{Bittersweet},
	keywords=[2]{linearsvc, pipeline, parammap, minmaxscaler, vectorassembler, crossvalidatormodel, linearregression, pipelinemodel, stringindexer, randomforestregressor, crossvalidator, regressionevaluator, regextokenizer, stopwordsremover, countvectorizer, hashingtf, logisticregression, paramgridbuilder, randomforestclassifier}, % ML-typen
	keywordstyle=[2]\color{purple},	
	keywords=[3]{private, static, final, throws, public, exception, call, udf4, udf2, new, return, system, printf}, 
	keywordstyle=[3]\color{violet},
	keywords=[4]{double, doubletype, timestamptype, stringtype, integertype, boolean , int, long, string, dataset},
	keywordstyle=[4]\color{RoyalBlue},
	keywords=[5]{label, prediction, verhouding, metric, spark},
	keywordstyle=[5]\color{Aquamarine}\bfseries,
	keywords=[6]{getTraining, getTest, clean, haversine, speed, printcorrelation, getarearoccurve, printconfusionmatrixmetrics, printregressionevaluation, getrangedataframe, getdata},
	keywordstyle=[6]\color{OliveGreen}\bfseries,
	keywords=[7]{where, select, first, orderby, groupby, count, show, drop, mean, sum, fit, transform, randomsplit, getdouble, withcolumn, union, sample, columns, weightedprecision, weightedrecall, accuracy},
	keywordstyle=[7]\color{PineGreen},
	keywords=[8]{pickuplatitude, pickuplongitude, dropofflatitude, dropofflongitude}, %input
	keywordstyle=[8]\color{Periwinkle},
	identifierstyle=\color{black},
	sensitive=false,
	comment=[l]{//},
	morecomment=[s]{/*}{*/},
	commentstyle=\color{red}\ttfamily,
	stringstyle=\color{Sepia}\ttfamily,
	morestring=[b]',
	morestring=[b]"
}

\lstset{ %
	backgroundcolor=\color{white},   
	basicstyle=\footnotesize,        
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	commentstyle=\color{commentsColor}\textit,
	deletekeywords={...},            % if you want to delete keywords from the given language
	escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
	extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
	frame=tb,	                   	   % adds a frame around the code
	keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
	keywordstyle=\color{keywordsColor},       % keyword style
	language=Python,                 % the language of the code (can be overrided per snippet)
	otherkeywords={*,...},           % if you want to add more keywords to the set
	numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
	numbersep=5pt,                   % how far the line-numbers are from the code
	numberstyle=\tiny\color{commentsColor}, % the style that is used for the line-numbers
	rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
	showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
	showstringspaces=false,          % underline spaces within strings only
	showtabs=false,                  % show tabs within strings adding particular underscores
	stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
	stringstyle=\color{stringColor}, % string literal style
	tabsize=2,	                   % sets default tabsize to 2 spaces
	title=\lstname,                  % show the filename of files included with \lstinputlisting; also try caption instead of title
	columns=fixed                    % Using fixed column width (for e.g. nice alignment)
}

\newfontfamily\headingfont[]{Montserrat-Black}

\usepackage[dutch]{babel}

\usepackage{fontspec}
\setmainfont{Montserrat}

\title{Verslag Distributed Databases}

\author{Dylan {Cluyse}, Laura {Renders}, Liam {Goethals}}
\date{11 december 2022}
\begin{document}
\maketitle

\tableofcontents

\chapter{Inleiding}

Tijdens het opleidingsonderdeel 'Distributed Databases' maakten wij kennis met Apache Spark. Spark biedt een data-analysetechnologie aan gericht op grootschalige gegevensverwerking. Deze technologie wordt aangeboden voor Java, Python, R en Scala. Voor dit opleidingsonderdeel gebruiken we Java als programmeertaal. Spark heeft pakketten dat zich richt op andere aspecten binnen dataverwerking, één daarvan is MLLib. MLLib biedt \textit{machine learning} technieken aan (ML). Wij kregen opdracht om via het platform Kaggle deel te nemen aan ML-gerichte competities, met het doel om zo meer vertrouwd te raken met ML en Spark.

In dit verslag nemen wij u mee in de wereld van ML met gebruik van Spark. Wij willen u met volle plezier enkele concrete casussen tonen die gebruik maken van de verschillende regressie- en classificatiemethoden.

Allereerst willen wij de tijdsduratie van een taxi-rit in downtown New York berekenen met regressie. Vervolgens detecteren wij kredietkaartfraude met behulp van binaire classificatie. Als derde oefening willen wij op basis van tekstinhoud achterhalen of een Tweet gerelateerd is aan een ramp. Tot slot geven wij u onze bevindingen mee van het MLLib pakket. Hier leggen we de aanpak van Spark en Sci-kit Learn, een pakket dat we in het opleidingsonderdeel Machine Learning zagen, parallel tegenover elkaar.

\chapter{Tijd van een taxi-verplaatsing voorspellen met regressie.}

\subsection*{Probleemstelling}

Als eerste opdracht maakten wij de "New York City Taxi Trip Duration" wedstrijd. De competitie voorziet twee datasets: een training- en een testset. Het doel is om de totale tijdsduur van een taxirit in seconden te berekenen. Deze competitie kiest de inzending met de kleinste \textit{Root Mean Square Log Error} (RMSLE). Volgende kolommen werden gegeven: 
\begin{itemize}
	\item De verkopersID
	\item Het aantal passagiers in een taxi.
	\item De longitude en latitude van het vertrekpunt.
	\item De longitude en latitude van het aankomstpunt.
	\item De pick-up en drop-off tijd.
\end{itemize}

De competitie kan u terugvinden op deze \href{http://bit.ly/3umBKN5}{link}. Wij namen inspiratie uit vooral de officiële documentatie en uit één notebook. De code, in \textit{Python}, kan u \href{http://bit.ly/3F2Aofj}{hier} terugvinden.

\subsection*{Algemeen}
Wij declareren \textit{final} variabelen. Deze worden meermaals gebruikt en worden niet aangepast doorheen de applicatie. Deze variabelen hebben een andere waarde bij de volgende twee oefeningen, maar ze komen in ieder model aan bod. De verhouding is de ratio waarop we de trainingset splitsen. De label is de kolom waarop ons model zal voorspellen. De prediction houdt de naam van de prediction-kolom bij. We houden de metriek bij dat we nodig hebben. Als laatste geven wij de metriek mee. Voorlopig kijken we naar het model met de beste RMSE waarde, daarop berekenen we de RMSLE.

\begin{lstlisting}[language=Java]
private static final double[] verhouding = { 0.8, 0.2 };
private static final String label = "target";
private static final String prediction = "prediction";
\end{lstlisting}

Uiteraard starten wij de applicatie met een Spark-object. Wij passen één instelling aan om zo de irrelevante CLI-informatie achterwege te laten.

\begin{lstlisting}[language=Java]
private static SparkSession spark = SparkSession.builder()
	.appName("DisasterTweet")
	.master("local[1]")
	.getOrCreate();
	
spark.sparkContext().setLogLevel("ERROR");
\end{lstlisting}

\newpage

\subsection*{Data ophalen}

De Kaggle-competitie bevat een training- en een testset. Dit in CSV-formaat. We kiezen ervoor om het schema vooraf op te bouwen. Dit geeft ons een snelheidsvoordeel, want met een \textit{pre-built} schema moet Spark zelf niet de datatypes achterhalen. Voor de datums werken wij met een \textit{Timestamp} type, want het bevat zowel de datum als het tijdstip wanneer een persoon werd opgehaald of afgezet. De code vindt u hieronder terug:
\begin{lstlisting}[language=Java]
	private static Dataset<Row> getTraining() {
	
	List<StructField> fields = Arrays.asList(
		DataTypes.createStructField("id", DataTypes.StringType, false),
		DataTypes.createStructField("vendor_id", DataTypes.DoubleType, false),
		DataTypes.createStructField("pickup_datetime", DataTypes.TimestampType, false),
		DataTypes.createStructField("dropoff_datetime", DataTypes.TimestampType, false),
		DataTypes.createStructField("passenger_count", DataTypes.DoubleType, false),
		DataTypes.createStructField("pickup_longitude", DataTypes.DoubleType, false),
		DataTypes.createStructField("pickup_latitude", DataTypes.DoubleType, false),
		DataTypes.createStructField("dropoff_longitude", DataTypes.DoubleType, false),
		DataTypes.createStructField("dropoff_latitude", DataTypes.DoubleType, false),
		DataTypes.createStructField("store_and_fwd_flag", DataTypes.StringType, false),
		DataTypes.createStructField("trip_duration", DataTypes.DoubleType, false)
	);
	
	StructType schemaData = DataTypes.createStructType(fields);
	
	Dataset<Row> dataset = spark.read()
		.option("header", true)
		.schema(schemaData)
		.csv("src/main/resources/train.csv");
	
	return dataset
		.withColumn("hour", hour(col("pickup_datetime")))
		.withColumn("day", dayofweek(col("pickup_datetime")))
		.drop("id", "pickup_datetime", "dropoff_datetime");
}

private static Dataset<Row> getTest() {
	List<StructField> fields = Arrays.asList(
		DataTypes.createStructField("id", DataTypes.StringType, false),
		DataTypes.createStructField("vendor_id", DataTypes.DoubleType, false),	
		DataTypes.createStructField("pickup_datetime", DataTypes.TimestampType, false),
		DataTypes.createStructField("passenger_count", DataTypes.DoubleType, false),
		DataTypes.createStructField("pickup_longitude", DataTypes.DoubleType, false),
		DataTypes.createStructField("pickup_latitude", DataTypes.DoubleType, false),
		DataTypes.createStructField("dropoff_longitude", DataTypes.DoubleType, false),
		DataTypes.createStructField("dropoff_latitude", DataTypes.DoubleType, false),
		DataTypes.createStructField("store_and_fwd_flag", DataTypes.StringType, false)
	);
	
	StructType schema = DataTypes.createStructType(fields);
	
	Dataset<Row> dataset = spark.read()
		.option("header", true)
		.schema(schema)
		.csv("src/main/resources/test.csv");
	
	return dataset.withColumn("hour", hour(col("pickup_datetime")))
		.withColumn("day", dayofweek(col("pickup_datetime")))
		.drop("id", "pickup_datetime");
}
\end{lstlisting}}

\pagebreak

\subsection*{Data Cleaning}

De data is te \textit{ruw}, en daarom maken wij een \textit{clean}-functie aan. Zonder de \textit{outliers} is het model nauwkeuriger. Wij passen het volgende stappenplan toe:

\begin{enumerate}
	\item De \textit{pick-up} en \textit{drop-off} datetime wordt meegegeven als datetime-object. We veranderen de datetime-kolommen \textit{pickuptime} naar \textit{hour} en \textit{day}. Zo krijgen we een pure numerieke waarde (bijvoorbeeld 1 tot en met 7 voor \textit{day}).
	\item We verwijderen de coördinaten-\textit{outliers} uit de dataset. Hiervoor kijken we naar de rijen met een veel te hoge \textit{longitude} en/of \textit{latitude}.

	\item We verwijderen de \textit{distance-outliers} uit de dataset. Dit gebeurt na het berekenen van de distance. De functie hiervoor komt zo dadelijk aan bod.
		
	\item We verwijderen alle rijen die géén passagiers meenemen. Alle rijen waar het aantal passagiers gelijk is aan 0 laten we vallen.
	
	\item We \textit{shufflen} de dataset. Dit wordt bij het splitsen nog eens gedaan, maar zo zijn we dubbel zeker dat er geen strikte volgorde is bij het splitsen.
\end{enumerate}

\begin{lstlisting}[language=Java]
private static Dataset<Row> clean(Dataset<Row> dataframe) {
	
	dataframe = dataframe.na().drop(); // alle rijen met null-waarden verwerpen
	
	double latMin = 40.6;
	double latMax = 40.9;
	double longMin = -74.25;
	double longMax = -73.7;
	
	// outliers verwerpen o.b.v. de longitude/latitude values
	dataframe = dataframe
		.where(col("pickup_longitude").$greater$eq(longMin))
		.where(col("dropoff_longitude").$greater$eq(longMin))
		.where(col("pickup_latitude").$greater$eq(latMin))
		.where(col("dropoff_latitude").$greater$eq(latMin))
		.where(col("pickup_longitude").$less$eq(longMax))
		.where(col("dropoff_longitude").$less$eq(longMax))
		.where(col("pickup_latitude").$less$eq(latMax))
		.where(col("dropoff_latitude").$less$eq(latMax));
	
	// outliers verwerpen o.b.v. de distance
	double rightOuter = dataframe
		.select(avg(col("distance")).plus(stddev(col("distance"))))
		.first()
		.getDouble(0);
		
	double leftOuter = dataframe
		.select(avg(col("distance")).minus(stddev(col("distance"))))
		.first()
		.getDouble(0);
		
	dataframe = dataframe
		.where(col("distance").$less$eq(rightOuter))
		.where(col("distance").$greater$eq(leftOuter));

	dataframe = dataframe
		.where(col("passenger_count").$greater(0)); // minstens één passagier in de taxi
	
	dataframe = dataframe
		.orderBy(rand()); // willekeurige volgorde
	
	return dataframe;
}
\end{lstlisting}

\newpage

\subsection*{User-Defined Functions}

De coördinaten van het vertrek- en aankomstpunt liggen te dicht bij elkaar. Daarnaast bieden deze vier waarden weinig inbreng aan het model. Daarom berekenen wij de afstand tussen de vertrek- en aankomstcoördinaten met de \textit{haversine}-formule, ofwel de formule om de grootcirkelafstand te berekenen. Deze formule dient om de afstand op een bol oppervlak te berekenen. Hiervoor maken we een \textit{user-defined-function} (UDF) aan dat vier parameters opvraagt: \textit{de pickup longitude, pickup latitude, de dropoff-longitude en de dropoff-latitude}. We volgen de wiskundige formule, in drie aparte stappen. Wiskundige bewerkingen, indien mogelijk zoals de vierkantswortel, doen we met de Math-library van Java.

\begin{lstlisting}[language=Java]
UDF4<Double, Double, Double, Double, Double> haversine = new UDF4<>() {
	public Double call(Double pickupLatitude, Double pickupLongitude, Double dropoffLatitude,
	Double dropoffLongitude) throws Exception {
		
		double radius = 6371 * 1.1; // Radius van de Aarde
		
		double lat1 = pickupLatitude;
		double lon1 = pickupLongitude;
		
		double lat2 = dropoffLatitude;
		double lon2 = dropoffLongitude;
		
		double deltaLat = Math.toRadians(lat2 - lat1);
		double deltaLon = Math.toRadians(lon2 - lon1);
		
		// Formule om de grootcirkelafstand te berekenen.
		double a = Math.sin(deltaLat / 2) * Math.sin(deltaLat / 2) + Math.cos(Math.toRadians(lat1)) * Math.cos(Math.toRadians(lat2)) * Math.sin(deltaLon / 2) * Math.sin(deltaLon / 2);
		
		double c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1 - a));
		
		double d = radius * c;
		
		return d;
	}
};
\end{lstlisting}

Wij willen ook de gemiddelde snelheid van een taxi in \textit{miles} per hour (mph) bekijken. Voor deze berekening maken wij een tweede UDF aan met als input-parameters: de totale afgelegde afstand en de totale tijdsduur van een rit. De output is de gemiddelde snelheid van een taxi per rit als kommagetal. De testset ontbreekt de verlopen tijd van een taxirit, dus we gebruiken deze kolom enkel als extra statistiek bij het analyseren van de data.

\begin{lstlisting}[language=Java]
UDF2<Double, Double, Double> speed = new UDF2<>() {
	public Double call(Double distance, Double time) throws Exception {
		return distance / (time / 3600);
	}
};
\end{lstlisting}

Als tussentijdse controle tonen wij, in de terminal, de gemiddelde snelheid en gemiddelde afstand per dag en uur. Zo controleren we de transformaties voor: \textit{distance, speed, hour en day}. Hieronder ziet u de gemiddelde afstand/snelheid per dag of per uur. 

\begin{lstlisting}[language=Java]
	train.groupBy("hour").mean("speed").orderBy("hour").show();
	train.groupBy("day").mean("speed").orderBy("day").show();
	
	train.groupBy("hour").sum("distance").orderBy("hour").show();
	train.groupBy("day").sum("distance").orderBy("day").show();
\end{lstlisting}

\newpage


\subsection*{Opbouwen van de pipeline}

Voor de pipeline werken we met vier stappen:

\begin{enumerate}
	\item We hebben een kolom met een vlag, ofwel een categorische tekstwaarde. Dit moeten we \textit{one-hot-encoden} of \textit{labelen}. In Spark gebruiken we een \textit{StringIndexer}.
	
	\item Spark MLLib verplicht dat we werken met een vector van feature-waarden. Alle kolommen omzetten naar één featurekolom doen we met een \textit{VectorAssembler}. 
	
	\item De waarden verschillen sterk qua grootte, en dit heeft een nadelig effect op ons model bij regressie. We moeten de waarden schalen. In Spark zijn er twee manieren: \textit{MinMaxScaling} en \textit{StandardScaling}. Wij gebruiken hier \textit{MinMaxScaler} wat de waarden tussen 0 en 1 zal plaatsen. De hoogste waarde zal dicht bij één aanleunen. De kleinste waarde zal dicht bij nul aanleunen.
	
	\item Als laatste object geven wij het regressiemodel mee. Wij testen vier verschillende modellen: lineaire regressie, \textit{Random Forest Regressor} (RFR), \textit{Gradient Boost Regressor} (GBR) en een gegeneraliseerd lineaire regressie (GLR). Wij vonden enkel het lineaire regressiemodel terug in de notebooks, maar uit interesse waagden wij een poging met drie extra modellen. 
	
\end{enumerate}

Hieronder vindt u de pipeline voor het lineaire regressiemodel. Dit model vindt u terug in de \textit{main}-methode.

\begin{lstlisting}[language=Java]
StringIndexer indexer = new StringIndexer()
	.setHandleInvalid("keep")
	.setInputCol("store_and_fwd_flag")
	.setOutputCol("flag_ind");

VectorAssembler assembler = new VectorAssembler()
	.setInputCols(new String[] { 
		"vendor_id", "passenger_count", "hour", "day", "flag_ind", "distance" 
	})
	.setOutputCol("features");

MinMaxScaler minMax = new MinMaxScaler()
	.setInputCol(assembler.getOutputCol())
	.setOutputCol("scaledFeatures");

LinearRegression linReg = new LinearRegression()
	.setLabelCol(label)
	.setFeaturesCol(minMax.getOutputCol());

Pipeline pipelineLinReg = new Pipeline()
	.setStages(new PipelineStage[] {
		 indexer, assembler, minMax, linReg 
	 });

PipelineModel model = pipelineLinReg.fit(trainSetSplit);
Dataset<Row> trainedLinReg = model.transform(trainTestSplit);
\end{lstlisting}

Bij \textit{machine learning} splitsen we de trainingsset in twee delen op. We stellen een vaste verhouding in door middel van een \textit{final} variabele. Wij kiezen voor de verhouding [80\% - 20\%]. Met de ingebouwde \textit{randomSplit} methode splitsen we de dataframe. 

\begin{lstlisting}[language=Java]
	Dataset<Row>[] datasets = train.randomSplit(verhouding, 42);
	Dataset<Row> trainSetSplit = datasets[0];
	Dataset<Row> trainTestSplit = datasets[1];
\end{lstlisting}

\newpage

\subsection*{Finetuning}

Om het meest optimale model te vinden, moeten we finetunen. In Spark pakken wij dit aan met een \textit{ParamGridBuilder}. Dit is het equivalent van werken met een \textit{GridSearch} in \textit{Sci-kit Learn}. Wij geven verschillende waarden per hyperparameter mee. Iedere combinatie zal worden getest. Hoe meer parameters, hoe langer de uitvoertijd van de applicatie. 

We passen crossvalidatie toe op ons model. Het beste model kiezen gebeurt op basis van een metriek. Zoals eerder gezegd willen we de beste RMSE hebben. Hieronder een voorbeeld van een RFR-pipeline met . We geven mee dat we voor de pipeline dezelfde objecten gebruiken als hierboven. Het \textit{tweaken} gebeurt binnenin de pipeline.

\begin{lstlisting}[language=Java]
RandomForestRegressor rfr = new RandomForestRegressor()
	.setLabelCol(label)
	.setFeaturesCol(minMax.getOutputCol());

ParamMap[] paramGridRFR = new ParamGridBuilder()
	.addGrid(rfr.maxDepth(), new int[] { 5, 10, 15 })
	.addGrid(rfr.numTrees(), new int[] { 10, 15, 20 })
	.build();

CrossValidator cvRFR = new CrossValidator()
	.setEstimator(rfr)
	.setEvaluator(regEval)
	.setEstimatorParamMaps(paramGridRFR);

Pipeline pipelineRFR = new Pipeline().setStages(new PipelineStage[] { indexer, assembler, minMax, cvRFR });
PipelineModel pipelineModelRFR = pipelineRFR.fit(trainSetSplit);
Dataset<Row> trainedRFR = pipelineModelRFR.transform(trainTestSplit);

printRegressionEvaluation(trainedRFR);
getRangeDataFrame(trainedRFR).show();

Dataset<Row> predictionsRFR = pipelineModelRFR.transform(test);
predictionsRFR.select(prediction).as("voorspelling RFR").show(5);
\end{lstlisting}


Een alternatief voor crossvalidatie is \textit{trainvalidationsplit} (TVS). Het verschil is dat TVS hier één datasetpaar maakt, terwijl crossvalidatie afhankelijk is van het aantal \textit{folds}. Dit gebruiken we bij GLR en GBR.

\begin{lstlisting}[language=Java]
GeneralizedLinearRegression glr = new GeneralizedLinearRegression()
	.setFamily("gaussian")
	.setLink("identity")
	.setLabelCol(label)
	.setFeaturesCol(minMax.getOutputCol()).setMaxIter(10).setRegParam(0.3);

ParamMap[] paramGridGLR = new ParamGridBuilder()
	.addGrid(glr.maxIter(), new int[] { 15, 20, 25 })
	.addGrid(glr.regParam(), new double[] { 0.6, 0.9 }).build();

TrainValidationSplit trainValidationSplitGLR = new TrainValidationSplit()
	.setEstimator(glr).setEvaluator(regEval)
	.setEstimatorParamMaps(paramGridGLR)
	.setTrainRatio(0.8);

Pipeline pipelineGLR = new Pipeline().setStages(new PipelineStage[] { indexer, assembler, minMax, trainValidationSplitGLR});

PipelineModel pipelineModelGLR = pipelineGLR.fit(trainSetSplit);
Dataset<Row> trainedGLR = pipelineModelGLR.transform(trainTestSplit);

printRegressionEvaluation(trainedRFR);
getRangeDataFrame(trainedRFR).show();

Dataset<Row> predictionsGLR = pipelineModelGLR.transform(test);
predictionsGLR.select(prediction).as("voorspelling GLR").show(5);
\end{lstlisting}



\newpage

\subsection*{Evaluatie en controle}

Het achterhalen van de interessante features doen we met een \textit{correlation matrix}.

\begin{lstlisting}[language=Java]
private static void printCorrelation(Dataset<Row> dataframe) {
	Row r1 = Correlation.corr(dataframe, "features").head();
	System.out.printf("\n\nCorrelation Matrix\n");
	Matrix matrix = r1.getAs(0);
	for (int i = 0; i < matrix.numRows(); i++) {
		for (int j = 0; j < matrix.numCols(); j++) {
			System.out.printf("%.2f \t", matrix.apply(i, j));
		}
		System.out.println();
	}
}
\end{lstlisting}

Met Crossvalidatie voorspelt het model met de meest optimale combinatie hyperparameters. Wij vragen de volgende metrieken op: \textit{Mean Squared Error} (MSE), \textit{Root Mean Squared Error} (RMSE), \textit{Mean Absolute Error} (MAE) en de R²-waarde. Als laatst berekenen we de RMSLE door de log-functie te gebruiken op de RMSE. Met een \textit{for}-lus kunnen wij voor iedere gevraagde metriek informatie ophalen.

\begin{lstlisting}[language=Java]
private static void printRegressionEvaluation(Dataset<Row> dataframe) {
	String[] metricTypes = { "mse", "rmse", "r2", "mae" };
	System.out.printf("\n\nMetrics:\n");
	for (String metricType : metricTypes) {
		RegressionEvaluator evaluator = new RegressionEvaluator()
			.setLabelCol(label)
			.setPredictionCol(prediction)
			.setMetricName(metricType);
		
		double calc = evaluator.evaluate(dataframe);
		System.out.printf("%s: \t%.5f \n", metricType, calc);
	}
	
	RegressionEvaluator evaluator = new RegressionEvaluator()
		.setLabelCol(label)
		.setPredictionCol(prediction)
		.setMetricName(metric);
	
	double calc = evaluator.evaluate(dataframe);
	double log = Math.log(calc);
	System.out.printf("%s: \t%.5f \n", "rmsle", log);
}
\end{lstlisting}

\newpage

Als laatste evaluatie willen we kijken naar de marge tussen de verschillende voorspelde waarden en de effectieve waarden. Zo weten we hoe sterk het model afwijkt en ook in hoeveel gevallen het in die mate afwijkt van de echte waarden. We werken met de volgende bereiken:

\begin{enumerate}
	\item 0-50 seconden
	\item 50-200 seconden
	\item 200-500 seconden
	\item 500-5000 seconden
	\item 5000+ seconden
\end{enumerate}}

\begin{lstlisting}[language=Java]
private static Dataset<Row> getRangeDataFrame(Dataset<Row> dataframe) {
	dataframe = dataframe.withColumn("margin",
		abs(col("prediction").minus(col("trip_duration"))));
	
	Dataset<Row> range = dataframe
	.withColumn("range",
		 when(col("margin").leq(50), "0-50")
		.when(col("margin").leq(200), "50-200")
		.when(col("margin").leq(500), "200-500")
		.when(col("margin").leq(5000), "500-5000")
		.otherwise("5000+"));	
	return range.groupBy("range").count();
}
\end{lstlisting}

\subsection*{Conclusie}

De opdracht vergde een stuk denkwerk. Om te oefenen, probeerden wij werkwijzen uit de documentatie toe te passen op vrij beschikbare datasets op Kaggle. Dit om te wennen aan de syntax en structuur. Enkele zaken uit de lessen kwamen hier aan bod. Zo moesten we twee \textit{UDF}'s implementeren om twee kolommen te berekenen, waaronder een kolom met de grootcirkelafstand. Op basis van \textit{groupby}'s kunnen we regelmatig data-analyse uitvoeren. Deze werkwijze hielp ons om outliers terug te vinden.

De resultaten van ons model vielen in lijn met andere \textit{notebooks} die deze technieken gebruikten. Notebooks dat regressiemodellen gebruikten, zoals \textit{XGBoost} wordt momenteel niet door Spark aangeboden. Daarnaast beschikten wij niet over een \textit{built-in} methode om de RMSLE te berekenen. Wij losten dit tijdelijk op door de log van de RMSE te berekenen. Na zoekwerk leidden wij af dat het logaritme van de RMSE berekenen een deelse oplossing was. \textit{Sci-kit Learn} biedt hiervoor een \textit{built-in} function aan.

\chapter{Kredietkaartfraude bestrijden met binaire classificatie. }

\subsection*{Probleemstelling}

Tijdens het zoeken van een classificatieprobleem stuiten wij ons op deze dataset. De dataset werd voor een competitie gebruikt, maar wij hadden geen toegang hiertoe. Deze dataset bestaat uit ongeveer 25.000 rijen. We hebben hier twee klassen: echte en fraudulente kredietkaarttransacties. We pakken dit probleem aan met een binair classificatiemodel. De dataset kan u \href{http://bit.ly/3iM6zIB}{hier} terugvinden. Voor deze oefening baseerden wij ons vooral op de nodige officiële documentatie om een classificatieprobleem in Spark aan te pakken. Wij namen inspiratie uit één notebook, dat u op deze \href{https://bit.ly/3Y9Kmo6}{link} kan terugvinden.

\subsection*{Data ophalen}

Voor deze opdracht krijgen we één dataset, namelijk \textit{creditcard.csv}. We hebben hier meer dan 30 features. Daarom kiezen we ervoor om geen apart schema aan te maken, maar we gebruiken de \textit{inferschema} optie van Spark. Zo achterhaalt Spark zelf het datatype van een kolom. \textit{Spark} herkent hier alle nodige features als een \textit{double}.

\begin{lstlisting}[language=Java]
private static Dataset<Row> getData() {
	return spark.read()
		.option("header", true).option("inferSchema", true)
		.csv("src/main/resources/creditcard.csv");
}
\end{lstlisting}

\subsection*{Data Cleanen}

De oorspronkelijke dataset is \textit{skewed}. Bij het bestuderen van de dataset merken we op dat 99.83\% van alle transacties echt zijn, terwijl enkel 0.71\% wél fraudulent is. Dit pakken we aan met een \textit{clean}-methode. Zonder deze methode hebben we een grotere kans op \textit{overfitting}, want het model neemt aan dat de meeste transacties echt zullen zijn. Als remedie maken we een \textit{sub-sample} van de volledige dataframe. We voorzien een 50:50 ratio tussen echte en fraudulente transacties.

\begin{lstlisting}[language=Java]
private static Dataset<Row> createSubSample(Dataset<Row> dataframe) {
	dataframe = dataframe.sample(1.0);
	dataframe = dataframe.orderBy(rand());
	Dataset<Row> nietFraudulent = dataframe.where(col(label).equalTo(1));
	long lengte = nietFraudulent.count();
	Dataset<Row> fraudulent = dataframe.where(col(label).equalTo(0)).limit((int) lengte);
	dataframe = nietFraudulent.union(fraudulent);
	return dataframe.sample(1.0);
}
\end{lstlisting}

\subsection*{Pipeline}

Alle nodige features starten met een 'V'-teken. Met behulp van een \textit{for-loop} en de \textit{startswith} methode kunnen wij de features zo aan een array van Strings toevoegen. Het alternatief is 28 features manueel ingeven bij het opstellen van de assembler. De \textit{assembler} zal de 28 kolommen omzetten naar één vector van features.

\begin{lstlisting}[language=Java]
String[] arrFeatures = new String[28];
int teller = 0;
for (String kolom : creditCardSubSample.columns()) {
	if (kolom.startsWith("V")) {
		arrFeatures[teller] = kolom;
		teller++;
	}
}
\end{lstlisting}

Het model bevat 28 features. Zelf kunnen we niet achterhalen welke er noodzakelijk zijn. Als uitprobeersel, en toepassing van een techniek uit de lessen \textit{Business Intelligence}, passen wij PCA toe aan de pipeline. Zo voorzien we \textit{dimensionality reduction} op op onze features. Zo behouden we enkel de features nodig voor het model. Voor de binaire classificatie keken wij naar drie verschillende classificatiemodellen: \textit{Random Forest, Lineaire SVM en logistische regressie}. Het tunen van de parameters doen we met een \textit{ParamGridBuilder}. 

\begin{lstlisting}[language=Java]
VectorAssembler assembler = new VectorAssembler()
	.setInputCols(arrFeatures).setOutputCol("features");
	
MinMaxScaler minmax = new MinMaxScaler()
	.setMax(1.0).setMin(0.0)
	.setInputCol("features")
	.setOutputCol("scaledFeatures");
	
PCA pca = new PCA()
	.setInputCol("scaledFeatures")
	.setOutputCol("pcaFeatures")
	.setK(3);

LinearSVC svc = new LinearSVC();

Pipeline pipelineSVM = new Pipeline()
	.setStages(new PipelineStage[] { assembler, minmax, pca, rfc });

ParamMap[] paramGridSVM = new ParamGridBuilder()
	.addGrid(svc.maxIter(), new int[] { 5, 10, 15 })
	.addGrid(svc.regParam(), new double[] { 0.1, 0.2, 0.3 })
	.addGrid(pca.k(), new int[] { 3, 6, 9 })
	.build();

CrossValidator cvSVM = new CrossValidator()
	.setEstimator(pipelineSVM)
	.setEvaluator(new BinaryClassificationEvaluator()
	.setLabelCol(label))
	.setEstimatorParamMaps(paramGridSVM);

CrossValidatorModel cvmSVM = cvSVM.fit(trainingSet);

Dataset<Row> predictionsSVM = cvmSVM.transform(testSet);
\end{lstlisting}

\newpage

\subsection*{Evaluatie}

We hebben een confusionmatrix nodig om het classificatiemodel te evalueren. Zo zien wij hoe goed het model de klassen kan voorspellen. Met de confusion matrix kunnen wij ook de precision en recall berekenen. Deze functies zijn ingebouwd in Spark, dus dit hoeven wij niet manueel te berekenen. Als laatste berekenen we de nauwkeurigheid van het model. Hieronder vindt u de twee methoden om de \textit{confusion matrix} weer te geven, en ook de methode om de nauwkeurigheid van het model op te halen.

\begin{lstlisting}[language=Java]
	private static double getAreaROCCurve(Dataset<Row> dataframe) {
	return new BinaryClassificationEvaluator()
		.setLabelCol(label)
		.evaluate(dataframe);
}

private static void printCorrelation(Dataset<Row> dataframe) {
	Row r1 = Correlation.corr(dataframe, "pcaFeatures").head();
	System.out.printf("\n\nCorrelation Matrix\n");
	Matrix matrix = r1.getAs(0);
	for (int i = 0; i < matrix.numRows(); i++) {
		for (int j = 0; j < matrix.numCols(); j++) {
			System.out.printf("%.2f \t", matrix.apply(i, j));
		}
		System.out.println();
	}
}

private static void printConfusionMatrixMetrics(Dataset<Row> dataframe) {
	dataframe = dataframe
		.select(prediction, label)
		.orderBy(prediction)
		.withColumn(label, col(label).cast("double"));
	
	MulticlassMetrics metrics = new MulticlassMetrics(dataframe);
	System.out.printf("Precision: %.5f \n", metrics.weightedPrecision());
	System.out.printf("Recall: %.5f \n", metrics.weightedRecall());
	System.out.printf("Recall: %.5f \n", metrics.accuracy());
}
\end{lstlisting}

Met een \textit{group-by} kunnen we een \textit{confusion matrix} opstellen. In de \textit{main}-methode spreken we de functies als volgt aan.

\begin{lstlisting}[language=Java]
System.out.printf("\n\nLogistische Regressie\n");
printConfusionMatrixMetrics(predictionsLogReg);
System.out.printf("Area ROC curve: %.4f\n", getAreaROCCurve(predictionsLogReg));
predictionsRFC.groupBy(col(label), col(prediction)).count().show(); 
\end{lstlisting}

\subsection*{Bevindingen}

Wij merken op dat zowel de Random Forest als de Lineaire SVM even sterk scoort. Het logistische regressiemodel daarentegen komt net iets te kort. Zo zijn er véél meer \textit{False Positives} vergeleken met de {False Negatives}. Dit wilt zeggen dat het model veel sneller een transactie goed zal keuren, terwijl het eigenlijk een fraudulente transactie is. Na hyperparameter tuning vonden wij geen oplossing. Onze eigen inbreng, PCA, heeft een kleine invloed gelaten op het model. Zo is de \textit{precision} met een kleine fractie verhoogd. 

\chapter{De inhoud van tweets detecteren met binaire NLP-classificatie.}

\subsection*{Probleemstelling}

Sociale media is een actueel onderwerp. Dubbelzinnige teksten spelen een grote rol. Voor deze opdracht moeten we, op basis van gegeven Engelstalige Tweets, achterhalen of een Tweet gerelateerd is aan een ramp of niet. De dubbelzinnigheid van een zin is een obstakel voor ons model. Zo kan een \textit{tweet} zeggen \textit{'look at the sky it was ablaze'} terwijl het woord \textit{ablaze} een andere context heeft. In deze zin is er een spreekwoordelijke betekenis. De tekst is ruw. Zo zijn er woorden en symbolen dat ons model kan hinderen. De link naar de competitie kan u \href{https://www.kaggle.com/c/nlp-getting-started}{hier} terugvinden. Wij baseerden ons vooral op de documentatie.

\subsection*{Data ophalen}

Deze oefening verschilt niet in aanpak. Wij krijgen de training- en testset mee in CSV-formaat. Dit lezen wij in met het Spark-object. Net zoals bij de regressie-oefening bouwen wij een schema op.

\begin{lstlisting}[language=Java]
private static Dataset<Row> getTraining() {
	List<StructField> fields = Arrays.asList(
		DataTypes.createStructField("id", DataTypes.IntegerType, false),
		DataTypes.createStructField("keyword", DataTypes.StringType, false),
		DataTypes.createStructField("location", DataTypes.StringType, false),
		DataTypes.createStructField("text", DataTypes.StringType, false),
		DataTypes.createStructField("target", DataTypes.DoubleType, false)
	);
	StructType schemaData = DataTypes.createStructType(fields);
	return spark.read()
		.option("header", true)
		.schema(schemaData)
		.csv("src/main/resources/train.csv");
}

private static Dataset<Row> getTest() {	
	List<StructField> fields = Arrays.asList(
		DataTypes.createStructField("id", DataTypes.IntegerType, false),
		DataTypes.createStructField("keyword", DataTypes.StringType, false),
		DataTypes.createStructField("location", DataTypes.StringType, false),
		DataTypes.createStructField("text", DataTypes.StringType, false)
	);
	StructType schemaData = DataTypes.createStructType(fields);
	return spark.read()
		.option("header", true)
		.schema(schemaData)
		.csv("src/main/resources/test.csv");
}
\end{lstlisting}

\subsection*{Data Cleaning}.

Voor we beginnen met teksttransformaties moeten we eerst de \textit{dataset} cleanen.

\begin{enumerate}
	\item We droppen alle rijen die \textit{null}-waarden bevatten.
	\item We voegen een \textit{string-only} kolom toe aan het dataframe. We behouden enkel de alfabetische karakters. We gaan er van uit dat we enkel met het Latijns alfabet te maken hebben. Arabische en Kanji-symbolen worden bijvoorbeeld weggefilterd.
	\item De data is licht \textit{skewed}. We willen een 50:50 verhouding hebben. Dit passen we aan met de \textit{createSubSample} methode. Deze is gelijkaardig aan de gelijknamige methode uit de vorige oefening.
	\item We splitsen de trainingset in twee: een \textit{trainSetSplit} en een \textit{trainTestSplit}. Ter controle printen we de lengte uit van beide dataframes.
\end{enumerate}

\begin{lstlisting}[language=Java]
train = train.select(col("id"), col("text"), col(label));
train = train.na().drop();
train = train.withColumn("text", regexp_replace(col("text"), "\\d+", ""));

test = test.select(col("id"), col("text"));
test = test.na().drop();
test = test.withColumn("text", regexp_replace(col("text"), "\\d+", ""));

train = createSubSample(train);
train.groupBy(label).count().show();

Dataset<Row>[] datasets = train.randomSplit(verhouding, 42);
Dataset<Row> trainSetSplit = datasets[0];
Dataset<Row> trainTestSplit = datasets[1];

System.out.printf("Lengte trainsetsplit: %s\n", trainSetSplit.count());
System.out.printf("Lengte testsetsplit: %s\n", trainTestSplit.count());
\end{lstlisting}

\subsection*{Pipeline}

We krijgen rauwe tekstdata binnen. Deze bevat niet-alfanumerieke karakters, overbodige spaties en stopwoorden. Deze woorden willen wij mijden in ons model. Om de tekstdata om te zetten naar bruikbare data voor ons model maken wij gebruik van een pipeline. Op het einde van de pipeline komt het classificatiemodel aan bod.

\begin{enumerate}
	\item We behouden enkel de alfanumerieke karakters. Alles met spaties en symbolen verwerpen we. Hiervoor gebruiken we een \textit{RegexTokenizer} object.
	\item Vervolgens willen we de stopwoorden verwijderen. Dit doen we met een \textit{StopWordsRemover}. Als de tweets in een andere taal waren, bijvoorbeeld Nederlands, dan hadden wij eerst de stopwoorden uit die taal moeten opladen. Vervolgens moeten wij die set van stopwoorden koppelen aan het model. Dit hoeven wij niet te doen.
	\item De gefilterde woorden moeten we, net zoals aparte featurekolommen bij het regressiemodel, gaan omzetten naar één featurekolom. Dit zal een vector zijn van alle woorden. In dit verslage gebruiken wij twee verschillende transformers: \textit{CountVectorizer} of \textit{HashingTF}. Hieronder ziet u een voorbeeld van een pipeline met HashingTF.
	\item Het einde van de rit: een classificatiemodel trainen en testen. Bij deze oefening testen we twee verschillende modellen uit: logistische regressie én een \textit{Random Forest Classifier}. Voor beide classificatiemodellen werken we met crossvalidatie.
\end{enumerate}

\newpage

Dit is de eerste pipeline. Hier werken we met Logistische regressie, inclusief crossvalidatie. De features worden naar een vector omgezet met \textit{HashingTF}.

\begin{lstlisting}[language=Java]
RegexTokenizer tokenizer = new RegexTokenizer()
	.setInputCol("text")
	.setOutputCol("words")
	.setPattern("\\W");

StopWordsRemover remover = new StopWordsRemover()
	.setInputCol(tokenizer.getOutputCol())
	.setOutputCol("filtered");

CountVectorizer vectorizer = new CountVectorizer()
	.setInputCol(remover.getOutputCol())
	.setOutputCol("features")
	.setVocabSize(10000)
	.setMinDF(5);

HashingTF htf = new HashingTF()
	.setInputCol(remover.getOutputCol())
	.setOutputCol("hashedFeatures");

LogisticRegression lr = new LogisticRegression()
	.setFeaturesCol(htf.getOutputCol())
	.setLabelCol(label)
	.setMaxIter(10)
	.setRegParam(0.001);

ParamMap[] paramGridLogReg = new ParamGridBuilder()
	.addGrid(lr.maxIter(), new int[] { 400 })
	.addGrid(lr.threshold(), new double[] { 0.7, 0.8, 0.9 })
	.build();

CrossValidator cvLogReg = new CrossValidator()
	.setEstimator(lr)
	.setEvaluator(new BinaryClassificationEvaluator().setLabelCol(label))
	.setEstimatorParamMaps(paramGridLogReg);

Pipeline pipelineLogReg = new Pipeline().setStages(new PipelineStage[] { tokenizer, remover, hashingTF, cvLogReg});
\end{lstlisting}

Hieronder ziet u ons tweede model: een \textit{RandomForestClassifier} dat \textit{CountVectorizer} gebruikt om de features naar één vector om te zetten.

\begin{lstlisting}[language=Java]
RandomForestClassifier rfc = new RandomForestClassifier()
	.setLabelCol(label)
	.setFeaturesCol(vectorizer.getOutputCol()).setSeed(42);
	
CountVectorizer vectorizer = new CountVectorizer()
	.setInputCol(remover.getOutputCol())
	.setOutputCol("features")
	.setVocabSize(10000)
	.setMinDF(5);

ParamMap[] paramGridRFC = new ParamGridBuilder()
	.addGrid(rfc.maxDepth(), new int[] { 5, 7, 10 })
	.addGrid(rfc.numTrees(), new int[] { 40, 80 })
	.build();

CrossValidator cvRFC = new CrossValidator()
	.setEstimator(rfc)
	.setEvaluator(new BinaryClassificationEvaluator().setLabelCol(label))
	.setEstimatorParamMaps(paramGridRFC).setNumFolds(5);

Pipeline pipelineRFC = new Pipeline()
	.setStages(new PipelineStage[] { tokenizer, remover, vectorizer, cvRFC});
\end{lstlisting}

\newpage

\subsection*{Evaluatie}

We evalueren het model op basis van de volgende metrieken:
\begin{itemize}
	\item Nauwkeurigheid
	\item De \textit{precision} en \textit{recall}.
	\item \textit{Area under ROC curve}
	\item De confusion matrix printen we uit met door een \textit{groupby} uit te voeren op het dataframe met de voorspelde waarden.
\end{itemize}

\begin{lstlisting}[language=Java]

// binnen klasse DisasterTweetClassification	
private static double getAreaROCCurve(Dataset<Row> dataframe) {
	return new BinaryClassificationEvaluator().setLabelCol(label).evaluate(dataframe);
}
	
private static void printConfusionMatrixMetrics(Dataset<Row> dataframe) {
	System.out.println();
	dataframe = dataframe.select(prediction, label).orderBy(prediction)
	.withColumn("target_d", col(label).cast("double")).drop(col(label));
	
	MulticlassMetrics metrics = new MulticlassMetrics(dataframe);
	System.out.printf("Precision: %.5f \n", metrics.weightedPrecision());
	System.out.printf("Recall: %.5f \n", metrics.weightedRecall());
	System.out.printf("Nauwkeurigheid: %.5f \n", metrics.accuracy());
}

// .. in Main-methode
PipelineModel pipelineModelLogReg = pipelineLogReg.fit(trainSetSplit);
Dataset<Row> predictedLogReg = pipelineModelLogReg.transform(trainTestSplit);
printConfusionMatrixMetrics(predictedLogReg);
System.out.printf("Area ROC Curve: %.4f\n", getAreaROCCurve(predictedLogReg));
predictedLogReg.groupBy(col(label), col(prediction)).count().show();
\end{lstlisting}

\subsection*{Bevindingen}

Beide modellen scoren hier even sterk. Noch het verschil tussen de \textit{HashingTF} en \textit{CountVectorizer}, noch het verschil tussen logistische regressie en \textit{Random Forest Classification} valt hier op. Er is een aanvaardbaar evenwicht tussen de \textit{false negatives} en \textit{false positives}.

\chapter{Conclusie}

\subsection*{Algemene bevindingen}

In het tweede jaar Data Engineering doken wij voor het eerst in de wereld van \textit{machine learning}. Tijdens de lessen werkten wij exclusief met de \textit{Python-library Scikit-Learn}. Spark MLlib was voor onze groep een nieuwe ervaring. Tijdens het maken van deze oefeningen merkten wij vier algemene punten op, waaronder drie gebreken en één voordeel.

De eerste kwaal is het debuggen. De luxe van de Python notebooks hebben wij hier niet meer. Een klein deel van de code uitvoeren, bijvoorbeeld het herladen van een dataset of het aanpassen van een model, is niet mogelijk. Alles moet vanaf nul worden opgestart. 

Als tweede punt ontbreekt Spark de nodige aanschouwelijkheid. Data visualiseren is niet mogelijk op een terminal en dit is nadelig om de ruwe data te analyseren. Tijdens de opdrachten gebruikten we de analytische functies van Spark, bijvoorbeeld het tellen van het aantal per klasse, om te kijken of de data \textit{skewed} is. Wij benaderen dit in de regressieoefening met een \textit{case-when}.  Daarnaast werkten wij met het gemiddelde en de standaardafwijking om alles buiten een bereik weg te laten. Alles binnen Spark met Java blijft \textit{terminal}-gebaseerd. Er bestaan alternatieven om grafieken te genereren. Na onderzoek kwamen wij uit op \textit{GraphFrames}. Met dit pakket kan je grafieken creëeren binnen Java. Dit is een deelse oplossing, want het is niet even eenvoudig als bij \textit{Matplotlib} met Python.

Toch komen de sterktepunten van Apache ook boven water. Spark en Python Pandas staan op een relatief gelijk niveau. Ze bieden een even krachtige oplossing voor data-analyse en data-manipulatie. Na verder onderzoek blijkt Spark toch een krachtige tool voor \textit{Machine Learning}. Zo is dit pakket ideaal om meerdere statistische berekeningen parallel op gigantische datasets uit te voeren. \textit{Sci-kit Learn} is eerder geschikt voor middelgrote datasets. Dit is iets wat wij als toekomstige \textit{data-engineers} best in het achterhoofd houden.

\subsection*{Conclusie}

Met het maken van drie distincte ML-oefeningen hebben wij een beter zicht gekregen op Spark MLlib. Dit pakket is een must wanneer je op de volgende twee vragen positief antwoord: 
\begin{enumerate}
	\item Wil ik zware rekenkrachtige toepassingen draaien op een gigantische hoeveelheid data?
	\item Is alle data verspreid over een \textit{distributed system}?
\end{enumerate}

We kunnen besluiten dat Spark Mllib een krachtig en veelzijdig platform is voor dataverwerking en \textit{machine learning}. Het biedt gebruikers de mogelijkheid om grote hoeveelheden gegevens snel en efficiënt te verwerken. Daarnaast biedt het een rijk aanbod aan machine learning-algoritmen en -hulpmiddelen. Hoewel er enkele uitdagingen en beperkingen zijn, het kan een waardevol hulpmiddel zijn wanneer je gegevens op grote schaal wil verwerken en analyseren.

\appendix

\end{document}